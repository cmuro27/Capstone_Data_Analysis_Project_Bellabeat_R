---
title: "Google Data Analytics Certificate. Capstone project: Bellabeat"
author: "César Muro Cabral"
date: "2023-01-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

This capstone project is part of the last course of Google Data Analytics Professional Certificate. 

In this case study, we answer key business questions for Bellabeat, a high-tech manufacturer of health-focused products for women.  

The tool used for this analysis is the R programming language used with the integrated development environment RStudio.

## Scenario

Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device. Urška Sršen, cofounder and Chief creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. We have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide marketing strategy for the company.

The primary Bellabeat products are  

* **Bellabeat app**: The Bellabeat app provides users with health data related to their activity, sleep, stress,
menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and
make healthy decisions. The Bellabeat app connects to their line of smart wellness products.

* **Leaf**: Bellabeat’s classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects
to the Bellabeat app to track activity, sleep, and stress.  

* **Time**: This wellness watch combines the timeless look of a classic timepiece with smart technology to track user
activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your
daily wellness.  

* **Spring**: This is a water bottle that tracks daily water intake using smart technology to ensure that you are
appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your
hydration levels.

Our data analysis will be divided en six consecutive phases: ask, prepare data, process and clean data, analyze, share and act.

# Ask phase

In this first phase, we define the problem by asking the right questions and identifying the stakeholders and their expectations.  

We can identify the key stakeholders as 

* **Urška Sršen**: Bellabeat’s cofounder and Chief Creative Officer.  

* **Sando Mur**: Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team.  

* **Bellabeat marketing analytics team**: A team of data analysts responsible for collecting, analyzing, and
reporting data that helps guide Bellabeat’s marketing strategy. You joined this team six months ago and have
been busy learning about Bellabeat’’s mission and business goals — as well as how you, as a junior data analyst,
can help Bellabeat achieve them

Sršen asks to analyze smart device usage data in order to gain insight into how consumers use non-Bellabeat smart
devices. She then wants you to select one Bellabeat product to apply these insights to in your presentation. These questions
will guide your analysis:  
 
  1. What are some trends in smart device usage?  
  
  2. How could these trends apply to Bellabeat customers?  
  
  3. How could these trends help influence Bellabeat marketing strategy?  
  
You will produce a report with the following deliverables: 

  1. A clear summary of the business task  
  
  2. A description of all data sources used  
  
  3. Documentation of any cleaning or manipulation of data  
  
  4. A summary of your analysis  
  
  5. Supporting visualizations and key findings  
  
  6. Your top high-level content recommendations based on your analysis  


# Collecting and preparing the data

At this phase, we collect and qualify the data and also analyze the data sources to check its validity.  

Sršen encourages to use public data that explores smart device users’ daily habits. She points you to use the [FitBit Fitness Tracker Data](https://www.kaggle.com/arashnic/fitbit). This Kaggle's dataset was generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016.  30 eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.  

The complete dataset is divided into 18 CSV files, in which a primary key column is an ID. This structured data is in a long format. These files are divided in daily, hourly and minute periods along the period 03.12.2016-05.12.2016. Notice that there are only two months of data, which can be considered a short period.    

The data integrity of this Kaggle's dataset is already measured and indicated in the usability icon. This data has a usability qualification of 10/10, with a score of 100 % in completeness, credibility, and compatibility.  

Moreover, this data has a licence of public domain CC0 1.0 Universal, which allows us to modify, and distribute it freely. 

## Loading the data in RStudio

I download the CSV files to a specific folder on my personal computer. Let us call the necessary libraries in R to load the data into data frames.

```{r}
library("tidyverse")
library("fs")
library("tools")
```
First, we define a list of characters with the names of the files in the folder; then, with the functions list.files(), and lapply(), we load all the CSV files (instead of calling them one by one) into a list of data frames. Finally, with the set_names() and file_path_sans_ext() functions, we name the files with their filename.

```{r}
file_directory <- fs::dir_ls("C:/Users/cmuro/Documents/dataset_google")
setwd("C:/Users/cmuro/Documents/dataset_google")
temp = list.files(pattern="*.csv",full.names = TRUE) 
myfiles = lapply(temp, read.csv)  
list_of_files <- set_names(myfiles, file_path_sans_ext(path_file(file_directory)))
```
I have not included the tables in wide format with the same data. 

Now, we use the glimpse function to get an overview of the dataframes. 

```{r}
glimpse(list_of_files)
```



Let us perform an evaluation of the data source with the ROCCC's criteria:  

* **R**eliable: This data is reliable since it has a suitable Kaggle usability qualification. Moreover, it was generated by a reliable company:  Fitbit, which is an American consumer electronics and fitness company that also produces wireless-enabled wearable technology, physical fitness monitors, and activity trackers such as smart watches, pedometers, and monitors for heart rate, quality of sleep and stairs climbed as well as related software.

* **O**riginal: It is original data.  

* **C**omprehensive: In general, this dataset needs to be more comprehensive. The numeric data must have units or some description. For example, there is a column called VeryActiveDistance with no specification of the distance units; some columns are repeated in other merged tables, etc. The most relevant is that there is no information about the sex, age, or disabilities of the 30 users. Bellabeat is a manufacturer of health-focused products for women, so not having these aspects will not allow us to make conclusions about the company's target.  

* **C**urrent: This data covers two months of 2016, then is not current.  

* **C**ited: This dataset has been employed for previous data analysis projects.

At this stage, it is important to mention that I consider that more comprehensive data is needed for a better analysis. Bellabeat is a company with products for women, and the data that we are employing does not specify age, sex, the region where the 30 users are from, etc. Moreover, I consider that a greater sample size is needed and with a long period of time, and not just two months of records.


# Processing and cleaning the data  

Here we find and eliminate any errors and data constraints that can get in the way of results. This usually means cleaning data transforming it into more useful format, combining two or more datasets to make information more complete and removing outliers or null data that could skew the information. 

I only focus on the daily and hourly files.   

For the daily data, the dailyActivity_merged, weightLogInfo_merged and the sleepDay_merged dataframes are the ones that collect all the necessary information. Then, from our list containing the dataframes we select them in indvidual dataframes

```{r}
daily_activity <- list_of_files["dailyActivity_merged"][[1]]
weight_info <- list_of_files["weightLogInfo_merged"][[1]]
sleep_activity <- list_of_files["sleepDay_merged"][[1]]
```

Notice that I have called the dataframes from list_of_files as if they have an extra dimension, this is usually common when working with a list of a list.  


We inspect their characteristics  

```{r}
str(daily_activity)
str(weight_info)
str(sleep_activity)
```
We observe that date columns needs to be converted to a date-time format which will be done at the analysis phase.   

In the daily_activity dataframe, the TotalDistance and TrackerDistance are the same. The LoggedActivityDistance and SedentaryActive distance are columns with just 0 values, we can do without them. Let us drop the previous both and TrackerDistance columns

```{r}
daily_activity$TrackerDistance <- NULL
daily_activity$SedentaryActiveDistance <- NULL
daily_activity$LoggedActivitiesDistance <- NULL
```



The column Fat of weight_info has several Na values, but we will only focus on the BMI column. I pretended to merge these three dataframes but since they have different number of rows it is not possible.  

Finally, we merge the three hourly dataframes since they have the number of columns  

```{r}
hourly_activity <- merge(list_of_files['hourlyCalories_merged'][[1]], list_of_files['hourlyIntensities_merged'][[1]],by=c("Id","ActivityHour")) %>% merge(list_of_files["hourlySteps_merged"][[1]],by=c("Id","ActivityHour"))
```

Let us look at its characteristics


```{r}
str(hourly_activity)
```


# Analyzing and visualizing the data

We load the libraries that we can consider relevant for the analysis

```{r}
library(tidyverse)
library(dplyr)
library(lubridate)
library(ggplot2)
library(Hmisc)
library(GGally)
library(skimr)
```
### Analyzing weight and body mass index

Let us investigate the corresponding dataframe with the weight and body mass index (bmi) of the users. 

We compute the relevant descriptive statistics

```{r}
weight_info_summary <- weight_info %>% group_by(Id) %>% summarise(total=n(),min_weight_kg=min(WeightKg),mean_weight_kg=mean(WeightKg),max_weight_kg=max(WeightKg),min_bmi=min(BMI),mean_bmi=mean(BMI),max_bmi=max(BMI)) %>% arrange(mean_bmi)
weight_info_summary
```

Unfortunately, there is only register of 8 different individuals.  

For adults 20 years and older, the BMI is interpreted using standard weight status categories. These categories are the same for men and women of all body types and ages.  

Let us inspect the status categories which belongs our individuals  

```{r}
weight_info_summary <- weight_info_summary %>% mutate( category_bmi = case_when(
mean_bmi<= 18.5 ~ "under_weight",
mean_bmi>18.5 & mean_bmi<=24.9 ~ "normal",
mean_bmi>=25 & mean_bmi<=29.9 ~ "over_weight" ,
mean_bmi>30 ~ "obesity"
))
weight_info_summary$category_bmi <- as.factor(weight_info_summary$category_bmi)
weight_info_summary
```

The percentage of each category is

```{r}
 prop.table(table(weight_info_summary$category_bmi))*100
```


Therefore, more than 62% percent of the users present over weight or obesity. This let us elucidate that the majority of individuals of our data are, in general, overweight.


```{r}
ggplot(weight_info_summary,aes(mean_bmi))+geom_boxplot(fill="blue",alpha=0.3)+scale_x_continuous(breaks=seq(0,60,by=2))+labs(x="Body mass index mean", title = "The users tend have overweight")
```

There is a relevant outlier; a person with a bmi of 47.54.   

### Analyzing the sleep activity data

Let us first convert the SleepDay column into date-time format with the function parse_date_time

```{r}
str(sleep_activity)
```

```{r}
sleep_activity$SleepDay <- parse_date_time(sleep_activity$SleepDay,    # Remove AM & PM from dates & times
                             "%m/%d/%y %I:%M:%S %p")
sleep_activity$week_day <- weekdays(sleep_activity$SleepDay)
sleep_activity <- sleep_activity %>% mutate(day_week=case_when( week_day=="domingo" ~ "Sunday", week_day=="lunes" ~ "Monday", week_day=="martes" ~ "Tuesday" , week_day=="miércoles" ~ "Wednesday", week_day=="jueves"  ~ "Thursday", week_day=="viernes" ~ "Friday", week_day=="sábado" ~ "Saturday"
))
```

then, we convert the columns of minutes to hours 

```{r}
sleep_activity$TotalMinutesAsleep <- sleep_activity$TotalMinutesAsleep/60
sleep_activity$TotalTimeInBed <- sleep_activity$TotalTimeInBed/60
sleep_activity <- rename(sleep_activity,TotalHoursAsleep=TotalMinutesAsleep)
```

We investigate the descriptive statistics of the dataframe

```{r}
skim(sleep_activity,TotalHoursAsleep,TotalTimeInBed)
```


We see that FitBit users have an average sleep around 6.9 hours per day and they and it takes them an average of 40 minutes to fall asleep.


```{r}
ggplot(sleep_activity)+geom_histogram(mapping = aes(x=TotalHoursAsleep,alpha=0.5),bins=25)+scale_y_continuous(breaks = seq(0,65,5) )+scale_x_continuous(breaks=1:20)+labs(x='Total hours Sleep',y='Frequencies',title = 'The users tend to be around 7.2 hours asleep per day')
ggplot(sleep_activity)+geom_histogram(mapping = aes(x=TotalTimeInBed,alpha=0.5),bins = 25)+scale_y_continuous(breaks = seq(0,65,5) )+scale_x_continuous(breaks=1:20)+labs(x='Total time in bed',y='Frequencies',title = 'The users tend to be around 7.7 hours in bed per day')
```
Moreover, we observe that the distribution of frequencies tends to follow a normal distribution.  


Let us find out how the FitBit users distribute their time in bed hours during the week

```{r}
databed <- sleep_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =TotalTimeInBed))+geom_boxplot(fill = "lightblue", color = "darkblue") +labs(x="Day of the Week", y="Total time in bed in hours")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
databed
q = c(.25, .5, .75)
sleep_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(TotalTimeInBed, probs = q[1]),quant50 = quantile(TotalTimeInBed, probs = q[2]),quant75 = quantile(TotalTimeInBed, probs = q[3]))
```

Therefore, the users lay to be more time in bed the Sundays and less on Fridays and Tuesdays.


We can examine if there is any relationship between the total time on bed and the body mass index.    


We obtain the mean of time in bed group by Id user


```{r}
sleep_activity_summary <- sleep_activity %>% group_by(Id) %>% summarise(total=n(),mean_time_in_bed=mean(TotalTimeInBed))
sleep_activity_summary
```

and merge both dataframes

```{r}
df <- merge(sleep_activity_summary,weight_info_summary,by="Id")
df
```

```{r}
ggplot(df,aes(x=mean_time_in_bed,y=mean_bmi,color=category_bmi))+geom_point()+scale_x_continuous(breaks=1:10)+labs(x='Total time in bed',y='Body mass index',title = 'There is not an appareant relationship between time in bed and body mass index')
```
We observe that there is no an apparent relationship between the total time in bed and the body mass index. 

### Analyzing the daily activity dataframe  

We explore the daily_activity dataframe and relate with the insights obtained previously.   

We transform the ActivityDate column into a date_time format and add new columns with the corresponding week day and the total active minutes.  

```{r}
daily_activity$ActivityDate <- parse_date_time(daily_activity$ActivityDate,    # Remove AM & PM from dates & times
                             "%m/%d/%y")
daily_activity$week_day <- weekdays(daily_activity$ActivityDate)
daily_activity <- daily_activity %>% mutate(day_week=case_when( week_day=="domingo" ~ "Sunday", week_day=="lunes" ~ "Monday", week_day=="martes" ~ "Tuesday" , week_day=="miércoles" ~ "Wednesday", week_day=="jueves"  ~ "Thursday", week_day=="viernes" ~ "Friday", week_day=="sábado" ~ "Saturday"
))
daily_activity$week_day <- NULL
daily_activity <- daily_activity %>% mutate(total_active_minutes=(VeryActiveMinutes+FairlyActiveMinutes+LightlyActiveMinutes))
str(daily_activity)
```


We obtain the descriptive statistics of each numeric column

```{r}
skim(select(daily_activity,-Id,-ActivityDate))
describe(daily_activity$day_week)
```



As we observe, the FitBit users spend much more time in a sedentary way than in an active way. Also, a light activity of walking is much greater than a very active one.


```{r}
select(daily_activity,day_week,VeryActiveDistance,ModeratelyActiveDistance,LightActiveDistance) %>% pivot_longer(-day_week,names_to ="Active_distances",values_to = "val") %>% mutate(Case=factor(Active_distances,levels = c("VeryActiveDistance","ModeratelyActiveDistance","LightActiveDistance"))) %>% ggplot(aes(x=day_week,y=val,fill=Case))+geom_col(position = position_stack(reverse = FALSE))+labs(x="Day of the week",y="Values",title="People have more activity on light distances")+scale_y_continuous(breaks = seq(0,900,by=50))

select(daily_activity,day_week,VeryActiveMinutes,FairlyActiveMinutes,LightlyActiveMinutes,SedentaryMinutes) %>% pivot_longer(-day_week,names_to ="Active_minutes",values_to = "val") %>% mutate(Case=factor(Active_minutes,levels = c("VeryActiveMinutes","FairlyActiveMinutes","LightlyActiveMinutes","SedentaryMinutes"))) %>% ggplot(aes(x=day_week,y=val,fill=Case))+geom_col(position = position_stack(reverse = FALSE))+labs(x="Day of the week",y="Values",title="Users spend much more time sedentary")+scale_y_continuous(breaks = seq(0,200000,by=20000))
```



Let us inspect how much time per day of the week the users of FitBit have activity 

```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =total_active_minutes/60))+geom_boxplot(fill = "lightblue", color = "darkblue")+scale_y_continuous(breaks=0:9) +labs(x="Day of the Week", y="Total active hours")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(total_active_minutes/60, probs = q[1]),quant50 = quantile(total_active_minutes/60, probs = q[2]),quant75 = quantile(total_active_minutes/60, probs = q[3]))
```
We observe that the persons spends around 4 hours per day on activity. On Tuesday is when they have more activity.


We also inspect how much sedentary time have the users.

```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =SedentaryMinutes/60))+geom_boxplot(fill = "lightblue", color = "darkblue")+scale_y_continuous(breaks=0:25) +labs(x="Day of the Week", y="Total sedentary hours")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(SedentaryMinutes/60, probs = q[1]),quant50 = quantile(SedentaryMinutes/60, probs = q[2]),quant75 = quantile(SedentaryMinutes/60, probs = q[3]))
```
They spend 18 hours per day in sedentary activities. The Thursdays are when they have less sedentary hours.


We examine the calories burned by users, the total steps, and total distance for each day of the week


```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =Calories))+geom_boxplot(fill = "lightblue", color = "darkblue")+scale_y_continuous(breaks = seq(0, 5000, by = 500)) +labs(x="Day of the Week", y="Calories")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(Calories, probs = q[1]),quant50 = quantile(Calories, probs = q[2]),quant75 = quantile(Calories, probs = q[3]))
```

The calorie burning does not vary significantly for each day of the week. It is a little higher on Tuesday.



```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =TotalSteps))+geom_boxplot(fill = "lightblue", color = "darkblue")+scale_y_continuous(breaks = seq(0, 50000, by = 2500))+labs(x="Day of the Week", y="Total steps")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(TotalSteps, probs = q[1]),quant50 = quantile(TotalSteps, probs = q[2]),quant75 = quantile(TotalSteps, probs = q[3]))
```

People walk more on Tuesday and then on Thursday.


```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =TotalDistance))+scale_y_continuous(breaks = seq(0, 30, by = 1))+geom_boxplot(fill = "lightblue", color = "darkblue")+labs(x="Day of the Week", y="Total distance")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(TotalDistance, probs = q[1]),quant50 = quantile(TotalDistance, probs = q[2]),quant75 = quantile(TotalDistance, probs = q[3]))
```

Let us check out if there is a relation between calories and active and sedentary minutes

```{r}
str(daily_activity)
```
```{r}
pm <- ggpairs(select(daily_activity,TotalDistance,total_active_minutes,SedentaryMinutes,Calories), lower = list(continuous = wrap("smooth", alpha=0.3,size=0.1,color="blue")) ,diag = list(continuous = "barDiag"),upper = list(continuous = wrap("cor", size = 4.5)),title="Scatter plots, histograms, and Pearson correlation factor")
pm + theme(axis.text = element_text(size = 9))
```

From this panel, we observe that total active minutes and total distance are positively correlated with calorie burn. Moreover, sedentary minutes is negative correlated but not so significantly as we might assume.



### Inspecting by grouping by id

Now, we group the data by id and compute the mean of each attribute

```{r}
by_id_active <- daily_activity %>% group_by(Id) %>% summarise(total=n(),mean_calories=mean(Calories),mean_sedentary_minutes=mean(SedentaryMinutes),mean_active_minutes=mean(total_active_minutes),mean_steps=mean(TotalSteps),mean_total_distance=mean(TotalDistance),mean_very_active_distance=mean(VeryActiveDistance),mean_light_active_distance=mean(LightActiveDistance))
by_id_active
```
Then, we analyze their correlation


```{r}
ggpairs(select(by_id_active,mean_sedentary_minutes,mean_active_minutes,mean_steps,mean_calories),lower = list(continuous = wrap("smooth", alpha=0.3,size=0.1,color="blue")) ,diag = list(continuous = "barDiag"),upper = list(continuous = wrap("cor", size = 4.5)),title="Scatter plots, histograms and Pearson correlation factor")
```

Similar to the previous panel, the total steps or total distance is positively correlated with calories, but sedentary minutes is not significantly correlated with them.

### Analyzing hourly_activity dataframe

Finally, let us examine how the total of steps, calories, and total intensity vary through each hour of the day.  


```{r}
hourly_activity$ActivityHour <- parse_date_time(hourly_activity$ActivityHour,    # Remove AM & PM from dates & times
                             "%m/%d/%y %I:%M:%S %p")
str(hourly_activity)
```

```{r}
summary_hourly_activity <- hourly_activity %>% group_by(factor(hour(ActivityHour))) %>% summarise(total=n(),mean_calories=mean(Calories),mean_total_intensity=mean(TotalIntensity),mean_step_total=mean(StepTotal))
```

```{r}
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_calories))+geom_bar(stat = "identity", fill = 4)+labs(x="time of the day",y="Mean of calories", title = "At the 18:00 hours is when more calories are burned")+scale_y_continuous(breaks = seq(0,130,by=10))
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_total_intensity))+geom_bar(stat = "identity", fill = 4)+labs(x="time of the day",y="Mean of intensity", title = "Intensity")+scale_y_continuous(breaks = seq(0,24,2))
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_step_total))+geom_bar(stat = "identity", fill = 4)+labs(x="time of the day",y="Mean of total steps", title = "Mean of total steps per hour of the day")+scale_y_continuous(breaks=seq(0,600,by=50))
```
Summarizing these plots, it is in the evening, around 6:00 pm, when FitBit users are most active.

# Share phase

Through the performed analysis, we found the following relevant facts:

```{r}
ggplot(weight_info_summary,aes(mean_bmi))+geom_boxplot(fill="blue",alpha=0.3)+scale_x_continuous(breaks=seq(0,60,by=2))+labs(x="Body mass index mean", title = "The users tend have overweight")
```

```{r}
ggplot(sleep_activity)+geom_histogram(mapping = aes(x=TotalHoursAsleep,alpha=0.5),bins=25)+scale_y_continuous(breaks = seq(0,65,5) )+scale_x_continuous(breaks=1:20)+labs(x='Total hours Sleep',y='Frequencies',title = 'They tend to be around 7.2 hours asleep per day')
ggplot(sleep_activity)+geom_histogram(mapping = aes(x=TotalTimeInBed,alpha=0.5),bins = 25)+scale_y_continuous(breaks = seq(0,65,5) )+scale_x_continuous(breaks=1:20)+labs(x='Total time in bed',y='Frequencies',title = 'And around 7.7 hours in bed per day')
```
Across the week

```{r}
select(daily_activity,day_week,VeryActiveDistance,ModeratelyActiveDistance,LightActiveDistance) %>% pivot_longer(-day_week,names_to ="Active_distances",values_to = "val") %>% mutate(Case=factor(Active_distances,levels = c("VeryActiveDistance","ModeratelyActiveDistance","LightActiveDistance"))) %>% ggplot(aes(x=day_week,y=val,fill=Case))+geom_col(position = position_stack(reverse = FALSE))+labs(x="Day of the week",y="Values",title="They have more activity on light distances")+scale_y_continuous(breaks = seq(0,900,by=50))

select(daily_activity,day_week,VeryActiveMinutes,FairlyActiveMinutes,LightlyActiveMinutes,SedentaryMinutes) %>% pivot_longer(-day_week,names_to ="Active_minutes",values_to = "val") %>% mutate(Case=factor(Active_minutes,levels = c("VeryActiveMinutes","FairlyActiveMinutes","LightlyActiveMinutes","SedentaryMinutes"))) %>% ggplot(aes(x=day_week,y=val,fill=Case))+geom_col(position = position_stack(reverse = FALSE))+labs(x="Day of the week",y="Values",title="and spend much more time sedentary")+scale_y_continuous(breaks = seq(0,200000,by=20000))
```
 being the Tuesdays and Thursdays when the present more activity. More specifically
 
 
```{r}
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_calories))+geom_bar(stat = "identity", fill = 4)+labs(x="hour of the day",y="Mean of calories", title = "At the 18:00 hours is when more calories are burned")+scale_y_continuous(breaks = seq(0,130,by=10))
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_total_intensity))+geom_bar(stat = "identity", fill = 4)+labs(x="hour of the day",y="Mean of intensity", title = " have more intensity ")+scale_y_continuous(breaks = seq(0,24,2))
ggplot(summary_hourly_activity,aes(x=summary_hourly_activity[[1]],y=mean_step_total))+geom_bar(stat = "identity", fill = 4)+labs(x="hour of the day",y="Mean of total steps", title = "and more total steps")+scale_y_continuous(breaks=seq(0,600,by=50))
```
 
However, 

```{r}
daily_activity %>%
  mutate(day_week = factor(day_week, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))) %>% 
  ggplot(aes(x = day_week, y =Calories))+geom_boxplot(fill = "lightblue", color = "darkblue")+scale_y_continuous(breaks = seq(0, 5000, by = 500)) +labs(x="Day of the Week", y="Value of calories" ,title="The burn of calories doest not vary significantly across the days of the week")+theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
q = c(.25, .5, .75)
daily_activity %>% group_by(day_week) %>% summarise(quant25 = quantile(Calories, probs = q[1]),quant50 = quantile(Calories, probs = q[2]),quant75 = quantile(Calories, probs = q[3]))
```

As we may have guessed from the beginning,


```{r}
pm <- ggpairs(select(daily_activity,TotalDistance,total_active_minutes,SedentaryMinutes,Calories), lower = list(continuous = wrap("smooth", alpha=0.3,size=0.1,color="blue")) ,diag = list(continuous = "barDiag"),upper = list(continuous = wrap("cor", size = 4.5)),title="Scatter plots, histograms, and Pearson correlation factor")
pm + theme(axis.text = element_text(size = 9))
```

more walking activity is positively correlated with the burning of calories. Nonetheless, according to our data, more sedentary activity is not necessarily negatively correlated with more calories burned.   

# Act phase - Recommendations

Therefore, I suggest the following recommendations:  

 * The use of intelligent devices is greater in sedentary people with little physical activity and slightly overweight. Therefore, the marketing strategy should have as its primary objective women who may have a more sedentary life, and their physical activities are more for their daily activities.
 
 * The publicity message could be that intelligent devices for health care are for all people, not just for fitness people.
 
 * The Bellabeat products, such as the watch, the leaf, and the app, easily adapt to daily activities. The message should include that these devices monitor your health all the time and recommend improving your health and physical activity through your daily activities. 
 
 * It is necessary to use current and more detailed data. A better study can be performed if we know more features of the users as their sex, their age, the place where they live, etc.

